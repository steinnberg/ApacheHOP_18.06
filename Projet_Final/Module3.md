# ğŸ“˜ Fiche pÃ©dagogique â€” Module 3
## Big Data : Hop + Spark (ou DuckDB)

---

## ğŸ¯ Objectifs pÃ©dagogiques
- Comprendre les limites du traitement local
- DÃ©couvrir le traitement distribuÃ©
- Adapter un pipeline ETL au Big Data

---

## ğŸ§  Apports thÃ©oriques

### 1. Pourquoi le Big Data ?
- Volume trop important pour une seule machine
- Temps de calcul excessif
- Besoin de parallÃ©lisation

---

### 2. Spark en bref
- DonnÃ©es rÃ©parties en partitions
- Calcul distribuÃ©
- TolÃ©rance aux pannes

---

## ğŸ§ª Cas concret guidÃ©

### Situation
Le dataset complet (800 Mo) doit Ãªtre traitÃ© en un temps raisonnable.

---

### Travail Ã  rÃ©aliser
1. ExÃ©cuter le pipeline en local
2. ExÃ©cuter le pipeline en distribuÃ©
3. Comparer :
   - temps
   - ressources
   - scalabilitÃ©

---

## ğŸ Livrables attendus
- Pipeline distribuÃ© fonctionnel
- RÃ©sultats agrÃ©gÃ©s
- Analyse comparative

---

## âœ… CritÃ¨res de rÃ©ussite
- Pipeline fonctionnel
- ComprÃ©hension des gains / limites
